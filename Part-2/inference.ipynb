{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label, transform):\n",
    "        self.data = torch.tensor(data).unsqueeze(-1).repeat(1, 1, 1, 3).numpy()\n",
    "        print(self.data.shape)\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx]), self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.13015008378839818,), (0.30690425774764835,)),\n",
    "    # transforms.Pad(padding=(0, 8,0,8)),\n",
    "    #  transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
    "    transforms.RandomResizedCrop((40, 20), scale=(0.7, 0.9), ratio=(0.9, 1.1)),   \n",
    "])\n",
    "\n",
    "\n",
    "transform_synth = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.13015008378839818,), (0.30690425774764835,)),\n",
    "    # transforms.Pad(padding=(0, 8,0,8)),\n",
    "    #  transforms.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
    "    transforms.RandomResizedCrop((40, 20), scale=(0.7, 0.9), ratio=(0.9, 1.1)),   \n",
    "])\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data',  # Directory where data will be stored\n",
    "    train=True,     # Get the training set\n",
    "    download=True,  # Download the dataset if it's not already present\n",
    "    transform=transform  # Apply the defined transformations\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,  # Get the test set\n",
    "    download=True,\n",
    "    transform=transform)\n",
    "    \n",
    "class SyntheticData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, label, transform = transform):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        length = self.__len__()\n",
    "        index = torch.randint(0, length, (4,),)\n",
    "        # print(index, length)\n",
    "        final_img = []\n",
    "        final_label = []\n",
    "\n",
    "        for i in range(4):\n",
    "            # print(self.data[index[i]].shape,)\n",
    "            final_img.append(self.transform(self.data[index[i]]))\n",
    "            final_label.append(self.label[index[i]])\n",
    "            # print(final_img[-1].shape)\n",
    "        \n",
    "\n",
    "        return torch.cat(final_img, -1), torch.stack(final_label, -1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super().__init__()\n",
    "        # Assuming input images are 40 x 168\n",
    "\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        self.num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(self.num_ftrs, 37)\n",
    "        self.model.fc.requires_grad_(True)\n",
    "        # self.fc = nn.Linear(self.flattened_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions = (predicted == labels).sum().item()\n",
    "        total_samples = labels.size(0)\n",
    "        accuracy = (correct_predictions / total_samples) * 100\n",
    "        running_accuracy += accuracy * images.shape[0]\n",
    "\n",
    "        # if idx % 10 == 1 :\n",
    "        #     print(accuracy, loss)\n",
    "        \n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_accuracy = running_accuracy / len(train_loader.dataset)\n",
    "    return epoch_loss, epoch_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 40, 168, 3)\n"
     ]
    }
   ],
   "source": [
    "input_channels = 1  \n",
    "num_classes = 37\n",
    "learning_rate = 0.001\n",
    "batch_size = 640\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = ConvNet(input_channels=input_channels, num_classes=num_classes).to(device)\n",
    "# criterion = nn.CrossEntropyLoss() \n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "test_data1 = np.load('data2.npy')\n",
    "test_lab1 = np.load('lab2.npy')\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # Repeat the single channel 3 times\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
    "])\n",
    "val_loader = torch.utils.data.DataLoader(MyData(test_data1, test_lab1, transform), batch_size=batch_size, num_workers=7)\n",
    "# transform = torchvision.transforms.Compose([\n",
    "#     torchvision.transforms.Resize((28,115)),\n",
    "#     torchvision.transforms.ToTensor(),\n",
    "# ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./resnet50-ema-model-epoch.pth').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.35054705786705015\n",
      "Validation accuracy: 90.59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "val_accuracy = 0.0\n",
    "with torch.no_grad():\n",
    "    for idx, (images, labels) in enumerate(val_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions = (predicted == labels).sum().item()\n",
    "        total_samples = labels.size(0)\n",
    "        val_accuracy += (correct_predictions / total_samples) * 100 * images.size(0)\n",
    "\n",
    "        # break\n",
    "val_loss /= len(val_loader.dataset)\n",
    "val_accuracy /= len(val_loader.dataset)\n",
    "\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Validation accuracy: {val_accuracy}' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import itertools\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super().__init__()\n",
    "        # Assuming input images are 40 x 168\n",
    "\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        self.num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.fc= nn.ModuleList([ nn.Linear(self.num_ftrs, 10) for _ in range(4)])\n",
    "        self.model.fc.requires_grad_(True)\n",
    "        # self.fc = nn.Linear(self.flattened_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x= self.model(x)\n",
    "        y = [ ]\n",
    "        for _ in range(4):\n",
    "            y.append(self.fc[_](x))\n",
    "    \n",
    "        return torch.stack(y, dim=-1)\n",
    "\n",
    "def special_validation(val_loader, model, criterion, device):\n",
    "    val_loss = 0.0\n",
    "    val_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, labels) in enumerate(tqdm.tqdm(val_loader)):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probab = outputs.softmax(-2).max(-2)[0].prod(-1)\n",
    "            # print(probab[:2], outputs.softmax(-2)[:2], outputs.softmax(-2).max(-2)[0][:2])\n",
    "            # print(-torch.log(probab).mean(), probab[:10])\n",
    "            # exit()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            predicted = outputs.argmax(-2).sum(-1)\n",
    "            correct_predictions = (predicted == labels).sum().item()\n",
    "            total_samples = labels.size(0)\n",
    "            val_accuracy += (correct_predictions / total_samples) * 100 * images.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy /= len(val_loader.dataset)\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "class CustomLoss():\n",
    "    def __init__(self):\n",
    "        numbers = list(range(10))  # Represents numbers 0 to 9\n",
    "        all_sets = torch.tensor(list(itertools.product(numbers, repeat=4))).detach()\n",
    "        self.all_sums = [[] for _ in range(37)]\n",
    "        for vector in all_sets:\n",
    "            sm = vector.sum()\n",
    "            self.all_sums[sm].append(vector)\n",
    "\n",
    "        for i in range(37):\n",
    "            # print(i, self.all_sums[0].shape)\n",
    "            self.all_sums[i] = torch.stack(self.all_sums[i], dim=0)\n",
    "\n",
    "    def calculate(self, logits, all_sum):\n",
    "        # logits are b x 10 x 4\n",
    "        probability = logits.softmax(dim=1)\n",
    "        loss = 0.0\n",
    "        # print(self.all_sums)\n",
    "        # construct b x number\n",
    "        for logit,one_sum  in zip(probability, all_sum):\n",
    "            # print(logit,one_sum)\n",
    "            all_prob = logit[self.all_sums[one_sum], torch.arange(4)]\n",
    "            loss += -torch.log(all_prob.prod(-1).sum())\n",
    "            # for vector4 in self.all_sums[one_sum]:\n",
    "\n",
    "            #     x = logit[vector4, torch.arange(4)].prod(-1)\n",
    "            #     print(logit[vector4, torch.arange(4)], vector4, logit[vector4, torch.arange(4)].prod(-1))\n",
    "            #     loss += x\n",
    "\n",
    "            # print(loss)\n",
    "        loss = loss/all_sum.shape[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 40, 168, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data1 = np.load('data2.npy')\n",
    "train_lab1 = np.load('lab2.npy')\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.060661207217261905,),(0.2193603594906726,)),\n",
    "])\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(MyData(train_data0, train_lab0, transform=transform_test), batch_size=batch_size, num_workers=5)\n",
    "test_loader = torch.utils.data.DataLoader(MyData(train_data1, train_lab1, transform=transform_test), batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./synthetic-ema-model-epoch.pth').to(device)\n",
    "ls  = CustomLoss()\n",
    "criterion2 = ls.calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.172992643356323\n",
      "Test accuracy: 53.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy =  special_validation(test_loader, model, criterion2, device)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test accuracy: {test_accuracy}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Minimal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
